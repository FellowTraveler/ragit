use super::Index;
use crate::chunk;
use crate::error::Error;
use crate::index::{ChunkBuildInfo, FileReader, IIStatus};
use crate::uid::Uid;
use ragit_api::record::Record;
use ragit_fs::{
    WriteMode,
    create_dir_all,
    exists,
    parent,
    write_bytes,
};
use sha3::{Digest, Sha3_256};
use std::collections::HashMap;

impl Index {
    pub async fn build(&mut self) -> Result<(), Error> {
        self.render_build_dashboard()?;

        let prompt = self.get_prompt("summarize")?;
        let mut hasher = Sha3_256::new();
        hasher.update(prompt.as_bytes());
        let prompt_hash = hasher.finalize();
        let prompt_hash = format!("{prompt_hash:064x}");
        let mut ii_buffer = HashMap::new();

        while let Some(doc) = self.staged_files.pop() {
            let real_path = Index::get_data_path(
                &self.root_dir,
                &doc,
            );

            let mut fd = FileReader::new(
                doc.clone(),
                real_path.clone(),
                self.build_config.clone(),
            )?;
            self.curr_processing_file = Some(doc.clone());
            let build_info = ChunkBuildInfo::new(
                fd.file_reader_key(),
                prompt_hash.clone(),
                self.api_config.model.to_human_friendly_name().to_string(),
            );
            let mut uids = vec![];
            let mut previous_summary = None;

            // index IN a file, not OF a file
            let mut file_index = 0;

            while fd.can_generate_chunk() {
                self.render_build_dashboard()?;
                let new_chunk = fd.generate_chunk(
                    &self,
                    &prompt,
                    build_info.clone(),
                    previous_summary.clone(),
                    file_index,
                ).await?;
                previous_summary = Some(new_chunk.summary.clone());
                let new_chunk_uid = new_chunk.uid;
                let new_chunk_path = Index::get_chunk_path(&self.root_dir, new_chunk_uid);
                uids.push(new_chunk_uid);

                // TODO: It's inefficient in that it might write the same image file multiple times.
                //       We have to run `self.add_image_description` before `chunk::save_to_file` because
                //       the latter requires the description files generated by the former.
                //       The good new is that it doesn't run `self.add_image_description` multiple times
                //       on the same image.
                for (uid, bytes) in fd.images.iter() {
                    let image_path = Index::get_image_path(&self.root_dir, *uid, "png");
                    let parent_path = parent(&image_path)?;

                    if !exists(&parent_path) {
                        create_dir_all(&parent_path)?;
                    }

                    write_bytes(
                        &image_path,
                        &bytes,
                        WriteMode::CreateOrTruncate,
                    )?;
                    self.add_image_description(*uid).await?;
                }

                file_index += 1;
                chunk::save_to_file(
                    &new_chunk_path,
                    &new_chunk,
                    self.build_config.compression_threshold,
                    self.build_config.compression_level,
                    &self.root_dir,
                )?;
                self.chunk_count += 1;

                match self.ii_status {
                    IIStatus::Complete => {
                        self.update_ii_buffer(&mut ii_buffer, new_chunk.uid)?;
                    },
                    IIStatus::Ongoing(_)
                    | IIStatus::Outdated => {
                        self.ii_status = IIStatus::Outdated;
                    },
                    IIStatus::None => {},
                }

                self.save_to_file()?;
            }

            let file_uid = Uid::new_file(&self.root_dir, &real_path)?;
            self.add_file_index(file_uid, &uids)?;
            self.flush_ii_buffer(ii_buffer)?;
            ii_buffer = HashMap::new();
            self.processed_files.insert(doc.clone(), file_uid);
            self.curr_processing_file = None;
            self.save_to_file()?;
        }

        self.render_build_dashboard()?;
        Ok(())
    }

    // TODO: erase lines instead of the entire screen
    fn render_build_dashboard(&self) -> Result<(), Error> {
        clearscreen::clear().expect("failed to clear screen");
        println!("staged files: {}, processed files: {}", self.staged_files.len(), self.processed_files.len());
        println!("chunks: {}", self.chunk_count);

        if let Some(file) = &self.curr_processing_file {
            println!("curr processing file: {file}");
        }

        else {
            println!("");
        }

        println!("model: {}", self.api_config.model.to_human_friendly_name());

        let api_records = self.api_config.get_api_usage("create_chunk_from")?;
        let mut input_tokens = 0;
        let mut output_tokens = 0;
        let mut input_cost = 0;
        let mut output_cost = 0;

        for Record { input, output, input_weight, output_weight, .. } in api_records.iter() {
            input_tokens += input;
            output_tokens += output;
            input_cost += input * input_weight;
            output_cost += output * output_weight;
        }

        println!(
            "input tokens: {input_tokens} ({:.3}$), output tokens: {output_tokens} ({:.3}$)",
            input_cost as f64 / 1_000_000_000.0,
            output_cost as f64 / 1_000_000_000.0,
        );
        Ok(())
    }
}
